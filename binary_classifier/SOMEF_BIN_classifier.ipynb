{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "from DNN import FFN\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model():\n",
    "    \n",
    "    def __init__(self,\n",
    "                 des_path,\n",
    "                 des_feat_path,\n",
    "                 install_path,\n",
    "                 install_feat_path,\n",
    "                 invoc_path,\n",
    "                 invoc_feat_path,\n",
    "                 cite_path,\n",
    "                 cite_feat_path\n",
    "                ):\n",
    "        self.desc = \"This class contains all four binary classifier\"\n",
    "        self.des_path = des_path\n",
    "        self.install_path = install_path\n",
    "        self.invoc_path = invoc_path\n",
    "        self.cite_path = cite_path\n",
    "        \n",
    "        self.des_feat_path = des_feat_path\n",
    "        self.install_feat_path = install_feat_path\n",
    "        self.invoc_feat_path = invoc_feat_path\n",
    "        self.cite_feat_path = cite_feat_path\n",
    "        \n",
    "        self.build()\n",
    "        \n",
    "    def build(self):\n",
    "        self.model_desc = torch.load(self.des_path)\n",
    "        self.model_install = torch.load(self.install_path)\n",
    "        self.model_invoc = torch.load(self.invoc_path)\n",
    "        self.model_cite = torch.load(self.cite_path)\n",
    "        \n",
    "        desc = pd.read_csv(self.des_feat_path).values\n",
    "        install = pd.read_csv(self.install_feat_path).values\n",
    "        invoc = pd.read_csv(self.invoc_feat_path).values\n",
    "        cite = pd.read_csv(self.cite_feat_path).values\n",
    "        self.desc_feat = {}\n",
    "        self.install_feat = {}\n",
    "        self.invoc_feat = {}\n",
    "        self.cite_feat = {}\n",
    "        for i in range(len(desc)):\n",
    "            self.desc_feat[desc[i][0]] = i\n",
    "        for i in range(len(install)):\n",
    "            self.install_feat[install[i][0]] = i\n",
    "        for i in range(len(invoc)):\n",
    "            self.invoc_feat[invoc[i][0]] = i\n",
    "        for i in range(len(cite)):\n",
    "            self.cite_feat[cite[i][0]] = i        \n",
    "\n",
    "        self.desc_vec = CountVectorizer(vocabulary = self.desc_feat)\n",
    "        self.install_vec = CountVectorizer(vocabulary = self.install_feat)\n",
    "        self.invoc_vec = CountVectorizer(vocabulary = self.invoc_feat)\n",
    "        self.cite_vec = CountVectorizer(vocabulary = self.cite_feat)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def inference(self,corpus):\n",
    "        new_corpus = list(map(self.lower_stopwords,corpus.split(\".\")))\n",
    "        encoded_corpus = self.desc_vec.transform(new_corpus).toarray()\n",
    "        o1 = self.model_desc(torch.tensor(encoded_corpus).float())\n",
    "        o2 = self.model_install(torch.tensor(encoded_corpus).float())\n",
    "        o3 = self.model_invoc(torch.tensor(encoded_corpus).float())\n",
    "        o4 = self.model_cite(torch.tensor(encoded_corpus).float())\n",
    "        desc_pred = torch.argmax(o1,dim=1)\n",
    "        install_pred = torch.argmax(o2,dim=1)\n",
    "        invoc_pred = torch.argmax(o3,dim=1)\n",
    "        cite_pred = torch.argmax(o4,dim=1)\n",
    "        return new_corpus,desc_pred,install_pred,invoc_pred,cite_pred\n",
    "    def lower_stopwords(self,x):\n",
    "        x = re.sub(r'[^a-zA-Z\\s]', '', x, re.I|re.A)\n",
    "        x = x.lower()\n",
    "        x = x.strip()\n",
    "        text_tokens = [word for word in word_tokenize(x) if word not in stopwords.words()]\n",
    "        return \" \".join(text_tokens)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['pandas python package provides fast flexible expressive data structures designed make working structured tabular multidimensional potenti ally heterogeneous time series data easy intu itive',\n",
       "  'aims fundamental highlevel building blo ck practical real world data analysis python',\n",
       "  'dditionally broader goal becoming power ful flexible open source data analysis manipulation tool vailable language',\n",
       "  'already well way toward goal',\n",
       "  ''],\n",
       " tensor([1, 1, 1, 1, 0]),\n",
       " tensor([1, 1, 1, 1, 0]),\n",
       " tensor([1, 1, 1, 1, 0]),\n",
       " tensor([1, 1, 1, 1, 0]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "des_path = \"../saved_models/DNN_description.pt\"\n",
    "des_feat_path = \"../saved_models/description_feat.csv\"\n",
    "\n",
    "install_path = des_path\n",
    "install_feat_path = des_feat_path\n",
    "\n",
    "invoc_path = des_path\n",
    "invoc_feat_path = des_feat_path\n",
    "\n",
    "cite_path = des_path\n",
    "cite_feat_path = des_feat_path\n",
    "\n",
    "classifier = model(des_path,\n",
    "                 des_feat_path,\n",
    "                 install_path,\n",
    "                 install_feat_path,\n",
    "                 invoc_path,\n",
    "                 invoc_feat_path,\n",
    "                 cite_path,\n",
    "                 cite_feat_path\n",
    "            )\n",
    "corpus = \"pandas is a Python package that provides fast,\\\n",
    "    flexible, and expressive data structures designed to make \\\n",
    "    working with structured (tabular, multidimensional, potenti\\\n",
    "    ally heterogeneous) and time series data both easy and intu\\\n",
    "    itive. It aims to be the fundamental high-level building blo\\\n",
    "    ck for doing practical, real world data analysis in Python. A\\\n",
    "    dditionally, it has the broader goal of becoming the most power\\\n",
    "    ful and flexible open source data analysis / manipulation tool a\\\n",
    "    vailable in any language. It is already well on its way toward this goal.\"\n",
    "classifier.inference(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = torch.load(\"../saved_models/DNN_description.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
