{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "from DNN import FFN\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model():\n",
    "    \n",
    "    def __init__(self,\n",
    "                 des_path,\n",
    "                 des_feat_path,\n",
    "                 install_path,\n",
    "                 install_feat_path,\n",
    "                 invoc_path,\n",
    "                 invoc_feat_path,\n",
    "                 cite_path,\n",
    "                 cite_feat_path\n",
    "                ):\n",
    "        self.desc = \"This class contains all four binary classifier\"\n",
    "        self.des_path = des_path\n",
    "        self.install_path = install_path\n",
    "        self.invoc_path = invoc_path\n",
    "        self.cite_path = cite_path\n",
    "        \n",
    "        self.des_feat_path = des_feat_path\n",
    "        self.install_feat_path = install_feat_path\n",
    "        self.invoc_feat_path = invoc_feat_path\n",
    "        self.cite_feat_path = cite_feat_path\n",
    "        \n",
    "        self.build()\n",
    "        \n",
    "    def build(self):\n",
    "        self.model_desc = torch.load(self.des_path)\n",
    "        self.model_install = torch.load(self.install_path)\n",
    "        self.model_invoc = torch.load(self.invoc_path)\n",
    "        self.model_cite = torch.load(self.cite_path)\n",
    "        \n",
    "        desc = pd.read_csv(self.des_feat_path).values\n",
    "        install = pd.read_csv(self.install_feat_path).values\n",
    "        invoc = pd.read_csv(self.invoc_feat_path).values\n",
    "        cite = pd.read_csv(self.cite_feat_path).values\n",
    "        self.desc_feat = {}\n",
    "        self.install_feat = {}\n",
    "        self.invoc_feat = {}\n",
    "        self.cite_feat = {}\n",
    "        for i in range(len(desc)):\n",
    "            self.desc_feat[desc[i][0]] = i\n",
    "        for i in range(len(install)):\n",
    "            self.install_feat[install[i][0]] = i\n",
    "        for i in range(len(invoc)):\n",
    "            self.invoc_feat[invoc[i][0]] = i\n",
    "        for i in range(len(cite)):\n",
    "            self.cite_feat[cite[i][0]] = i        \n",
    "\n",
    "        self.desc_vec = CountVectorizer(vocabulary = self.desc_feat)\n",
    "        self.install_vec = CountVectorizer(vocabulary = self.install_feat)\n",
    "        self.invoc_vec = CountVectorizer(vocabulary = self.invoc_feat)\n",
    "        self.cite_vec = CountVectorizer(vocabulary = self.cite_feat)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def inference(self,corpus):\n",
    "        new_corpus = list(map(self.lower_stopwords,corpus.split(\".\")))\n",
    "        encoded_corpus_desc = self.desc_vec.transform(new_corpus).toarray()\n",
    "        encoded_corpus_install = self.install_vec.transform(new_corpus).toarray()\n",
    "        encoded_corpus_invoc = self.invoc_vec.transform(new_corpus).toarray()\n",
    "        encoded_corpus_cite = self.cite_vec.transform(new_corpus).toarray()\n",
    "        \n",
    "        o1 = self.model_desc(torch.tensor(encoded_corpus_desc).float())\n",
    "        o2 = self.model_install(torch.tensor(encoded_corpus_install).float())\n",
    "        o3 = self.model_invoc(torch.tensor(encoded_corpus_invoc).float())\n",
    "        o4 = self.model_cite(torch.tensor(encoded_corpus_cite).float())\n",
    "        desc_pred = torch.argmax(o1,dim=1).detach().numpy()\n",
    "        install_pred = torch.argmax(o2,dim=1).detach().numpy()\n",
    "        invoc_pred = torch.argmax(o3,dim=1).detach().numpy()\n",
    "        cite_pred = torch.argmax(o4,dim=1).detach().numpy()\n",
    "        return corpus.split(\".\"),desc_pred,install_pred,invoc_pred,cite_pred\n",
    "    def lower_stopwords(self,x):\n",
    "        x = re.sub(r'[^a-zA-Z\\s]', '', x, re.I|re.A)\n",
    "        x = x.lower()\n",
    "        x = x.strip()\n",
    "        text_tokens = [word for word in word_tokenize(x) if word not in stopwords.words()]\n",
    "        return \" \".join(text_tokens)\n",
    "    def show_result(self,corpus):\n",
    "        new_corpus,desc_pred,install_pred,invoc_pred,cite_pred = self.inference(corpus)\n",
    "        for i in range(len(new_corpus)): \n",
    "            text = new_corpus[i]\n",
    "            label = []\n",
    "            if(desc_pred[i]==1):\n",
    "                label.append(\"descripetion\")\n",
    "            if(install_pred[i]==1):\n",
    "                label.append(\"installation\")\n",
    "            if(invoc_pred[i]==1):\n",
    "                label.append(\"invocation\")\n",
    "            if(cite_pred[i]==1):\n",
    "                label.append(\"citation\")\n",
    "            text += \" ->\" + str(tuple(label))\n",
    "            print(text)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GitHub - snap-stanford/ogb: Benchmark datasets, data loaders, and evaluators for graph machine learningnSkip to contentnSign upnWhy GitHub?nFeatures →nCode reviewnProject managementnIntegrationsnActionsnPackagesnSecuritynTeam managementnHostingnMobilenCustomer stories →nSecurity →nTeamnEnterprisenExplorenExplore GitHub →nLearn & contributenTopicsnCollectionsnTrendingnLearning LabnOpen source guidesnConnect with othersnEventsnCommunity forumnGitHub EducationnGitHub Stars programnMarketplacenPricingnPlans →nCompare plansnContact SalesnNonprofit →nEducation →nIn this repositorynAll GitHubn↵nJump ton↵nNo suggested jump to resultsnIn this repositorynAll GitHubn↵nJump ton↵nIn this repositorynAll GitHubn↵nJump ton↵nSign innSign upnsnap-stanfordn/nogbnWatchn34nStarn615nForkn84nBenchmark datasets, data loaders, and evaluators for graph machine learningnogb ->('descripetion',)\nstanford ->('installation', 'invocation')\nedunMIT Licensen615nstarsn84nforksnStarnWatchnCodenIssuesn0nPull requestsn0nActionsnProjectsn0nSecuritynInsightsnMorenCodenIssuesnPull requestsnActionsnProjectsnSecuritynInsightsnDismissnJoin GitHub todaynGitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together ->('descripetion',)\nnSign upnmastern1nbranchn7ntagsnGo to filenCodenClonenHTTPSnGitHub CLInUse Git or checkout with SVN using the web URL ->('installation',)\nnWork fast with our official CLI ->('descripetion', 'invocation')\nnLearn more ->('installation', 'invocation')\nnOpen with GitHub DesktopnDownload ZIPnLaunching GitHub DesktopnIf nothing happens, download GitHub Desktop and try again ->('descripetion', 'installation')\nnGo backnLaunching GitHub DesktopnIf nothing happens, download GitHub Desktop and try again ->('installation',)\nnGo backnLaunching XcodenIf nothing happens, download Xcode and try again ->('installation', 'invocation')\nnGo backnLaunching Visual StudionIf nothing happens, download the GitHub extension for Visual Studio and try again ->('descripetion', 'installation')\nnGo backnLatest commitnweihua916nAdding the link to raw texts for ogbn-arxivn…nda100e0nOct 29, 2020nAdding the link to raw texts for ogbn-arxivnda100e0nGit statsn375ncommitsnFilesnPermalinknFailed to load latest commit information ->()\nnTypenNamenLatest commit messagenCommit timenexamplesnAdding the link to raw texts for ogbn-arxivnOct 29, 2020nogbnAdd pre_transform to InMemoryDataset's init (pyg)nSep 29, 2020n ->('invocation',)\ngitignorenDatasaver + read binary logicnSep 3, 2020nLICENSEnadd codenDec 13, 2019nMANIFEST ->('installation', 'invocation')\ninnfix setup ->('installation', 'invocation')\npynDec 13, 2019nREADME ->('installation', 'invocation')\nmdnrequire python 3 ->('installation',)\n6nOct 9, 2020nsetup ->('installation', 'invocation')\npynrequire python 3 ->('installation',)\n6nOct 9, 2020nView codenREADME ->('installation', 'invocation')\nmdnOverviewnThe Open Graph Benchmark (OGB) is a collection of benchmark datasets, data loaders, and evaluators for graph machine learning ->('descripetion',)\n Datasets cover a variety of graph machine learning tasks and real-world applications ->('descripetion',)\nnThe OGB data loaders are fully compatible with popular graph deep learning frameworks, including PyTorch Geometric and Deep Graph Library (DGL) ->('descripetion',)\n They provide automatic dataset downloading, standardized dataset splits, and unified performance evaluation ->('descripetion', 'invocation')\nnOGB aims to provide graph datasets that cover important graph machine learning tasks, diverse dataset scale, and rich domains ->('descripetion',)\nnGraph ML Tasks: We cover three fundamental graph machine learning tasks: prediction at the level of nodes, links, and graphs ->('descripetion',)\nnDiverse scale: Small-scale graph datasets can be processed within a single GPU, while medium- and large-scale graphs might require multiple GPUs or clever sampling/partition techniques ->('descripetion',)\nnRich domains: Graph datasets come from diverse domains ranging from scientific ones to social/information networks, and also include heterogeneous knowledge graphs ->('descripetion',)\nnOGB is an on-going effort, and we are planning to increase our coverage in the future ->('installation',)\nnInstallationnYou can install OGB using Python's package manager pip ->('installation',)\nnIf you have previously installed ogb, please make sure you update the version to 1 ->('installation',)\n2 ->('installation', 'invocation')\n3 ->('installation', 'invocation')\nnThe release note is available here ->('installation',)\nnRequirementsnPython>=3 ->('installation', 'invocation')\n6nPyTorch>=1 ->('installation', 'invocation')\n2nDGL>=0 ->('installation', 'invocation')\n5 ->('installation', 'invocation')\n0 or torch-geometric>=1 ->('installation', 'invocation')\n6 ->('installation', 'invocation')\n0nNumpy>=1 ->('installation', 'invocation')\n16 ->('installation', 'invocation')\n0npandas>=0 ->('installation', 'invocation')\n24 ->('installation', 'invocation')\n0nurllib3>=1 ->('installation', 'invocation')\n24 ->('installation', 'invocation')\n0nscikit-learn>=0 ->('installation', 'invocation')\n20 ->('installation', 'invocation')\n0noutdated>=0 ->('installation', 'invocation')\n2 ->('installation', 'invocation')\n0nNote: torch-geometric>=1 ->('installation', 'invocation')\n6 ->('installation', 'invocation')\n0 is recommended to run our example code ->('installation', 'invocation')\nnPip installnThe recommended way to install OGB is using Python's package manager pip:npip install ogbnpython -c \"import ogb; print(ogb ->('installation',)\n__version__)\"n# This should print \"1 ->('invocation',)\n2 ->('installation', 'invocation')\n3\" ->('installation', 'invocation')\n Otherwise, please update the version bynpip install -U ogbnFrom sourcenYou can also install OGB from source ->('installation',)\n This is recommended if you want to contribute to OGB ->('installation', 'invocation')\nngit clone https://github ->('installation',)\ncom/snap-stanford/ogbncd ogbnpip install -e  ->('installation', 'invocation')\nnPackage UsagenWe highlight two key features of OGB, namely, (1) easy-to-use data loaders, and (2) standardized evaluators ->('descripetion', 'invocation')\nn(1) Data loadersnWe prepare easy-to-use PyTorch Geometric and DGL data loaders ->('descripetion', 'invocation')\n We handle dataset downloading as well as standardized dataset splitting ->('invocation',)\nnBelow, on PyTorch Geometric, we see that a few lines of code is sufficient to prepare and split the dataset! Needless to say, you can enjoy the same convenience for DGL!nfrom ogb ->('descripetion', 'installation')\ngraphproppred import PygGraphPropPredDatasetnfrom torch_geometric ->('invocation',)\ndata import DataLoaderndataset = PygGraphPropPredDataset(name = 'ogbg-molhiv')nsplit_idx = dataset ->('invocation',)\nget_idx_split()ntrain_loader = DataLoader(dataset[split_idx['train']], batch_size=32, shuffle=True)nvalid_loader = DataLoader(dataset[split_idx['valid']], batch_size=32, shuffle=False)ntest_loader = DataLoader(dataset[split_idx['test']], batch_size=32, shuffle=False)n(2) EvaluatorsnWe also prepare standardized evaluators for easy evaluation and comparison of different methods ->('descripetion', 'invocation')\n The evaluator takes input_dict (a dictionary whose format is specified in evaluator ->('invocation',)\nexpected_input_format) as input, and returns a dictionary storing the performance metric appropriate for the given dataset ->('descripetion', 'invocation')\nnThe standardized evaluation protocol allows researchers to reliably compare their methods ->('descripetion',)\nnfrom ogb ->('installation', 'invocation')\ngraphproppred import Evaluatornevaluator = Evaluator(name = 'ogbg-molhiv')n# You can learn the input and output format specification of the evaluator as follows ->('descripetion', 'invocation')\nn# print(evaluator ->('installation', 'invocation')\nexpected_input_format)n# print(evaluator ->('installation', 'invocation')\nexpected_output_format)ninput_dict = {'y_true': y_true, 'y_pred': y_pred}nresult_dict = evaluator ->('installation', 'invocation')\neval(input_dict) # E ->('installation', 'invocation')\ng ->('installation', 'invocation')\n, {'rocauc': 0 ->('installation', 'invocation')\n7321}nCiting OGBnIf you use OGB datasets in your work, please cite our paper (Bibtex below) ->('citation',)\nn@article{hu2020ogb,ntitle={Open Graph Benchmark: Datasets for Machine Learning on Graphs},nauthor={Weihua Hu, Matthias Fey, Marinka Zitnik, Yuxiao Dong, Hongyu Ren, Bowen Liu, Michele Catasta, Jure Leskovec},njournal={arXiv preprint arXiv:2005 ->('descripetion', 'citation')\n00687},nyear={2020}n}nAboutnBenchmark datasets, data loaders, and evaluators for graph machine learningnogb ->('descripetion', 'invocation')\nstanford ->('installation', 'invocation')\nedunTopicsngraph-machine-learningngraph-neural-networksndeep-learningndatasetsnResourcesnReadmenLicensenMIT LicensenReleasesn7n1 ->('installation', 'invocation')\n2 ->('installation', 'invocation')\n3nLatestnSep 12, 2020n+ 6 releasesnPackages 0nNo packages publishednContributors 8nLanguagesnPythonn100 ->('installation', 'invocation')\n0%n© 2020 GitHub, Inc ->('installation',)\nnTermsnPrivacynCookie PreferencesnSecuritynStatusnHelpnContact GitHubnPricingnAPInTrainingnBlognAboutnYou can’t perform that action at this time ->('descripetion',)\nnYou signed in with another tab or window ->('installation',)\n Reload to refresh your session ->('installation', 'invocation')\nnYou signed out in another tab or window ->('installation', 'invocation')\n Reload to refresh your session ->('installation', 'invocation')\nnWe use optional third-party analytics cookies to understand how you use GitHub ->('installation', 'citation')\ncom so we can build better products ->('descripetion', 'installation', 'invocation')\nnLearn more ->('installation', 'invocation')\nnAcceptnRejectnWe use optional third-party analytics cookies to understand how you use GitHub ->('installation', 'citation')\ncom so we can build better products ->('installation',)\nnYou can always update your selection by clicking Cookie Preferences at the bottom of the page ->('descripetion', 'installation')\nnFor more information, see our Privacy Statement ->('invocation',)\nnEssential cookiesnWe use essential cookies to perform essential website functions, e ->('descripetion',)\ng ->('installation', 'invocation')\n they're used to log you in ->('installation', 'invocation')\nnLearn morenAlways activenAnalytics cookiesnWe use analytics cookies to understand how you use our websites so we can make them better, e ->('invocation',)\ng ->('installation', 'invocation')\n they're used to gather information about the pages you visit and how many clicks you need to accomplish a task ->('descripetion',)\nnLearn morenAcceptnRejectnSave preferences ->('installation',)\n"
     ]
    }
   ],
   "source": [
    "des_path = \"../saved_models/DNN_description.pt\"\n",
    "des_feat_path = \"../saved_models/description_feat.csv\"\n",
    "\n",
    "install_path = \"../saved_models/DNN_install.pt\"\n",
    "install_feat_path = \"../saved_models/install_feat.csv\"\n",
    "\n",
    "invoc_path = \"../saved_models/DNN_invocation.pt\"\n",
    "invoc_feat_path = \"../saved_models/invocation_feat.csv\"\n",
    "\n",
    "cite_path = \"../saved_models/DNN_citation.pt\"\n",
    "cite_feat_path = \"../saved_models/citation_feat.csv\"\n",
    "\n",
    "classifier = model(des_path,\n",
    "                 des_feat_path,\n",
    "                 install_path,\n",
    "                 install_feat_path,\n",
    "                 invoc_path,\n",
    "                 invoc_feat_path,\n",
    "                 cite_path,\n",
    "                 cite_feat_path\n",
    "            )\n",
    "# create input\n",
    "url = input()\n",
    "response = urllib.request.urlopen(url)\n",
    "page = response.read()\n",
    "soup = BeautifulSoup(page, \"lxml\")\n",
    "# kill all script and style elements\n",
    "for script in soup([\"script\", \"style\"]):\n",
    "   script.extract()    # rip it out\n",
    "# get text\n",
    "text = soup.get_text()\n",
    "# break into lines and remove leading and trailing space on each\n",
    "lines = (line.strip() for line in text.splitlines())\n",
    "# break multi-headlines into a line each\n",
    "chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "# drp blank lines\n",
    "text = 'n'.join(chunk for chunk in chunks if chunk)\n",
    "\n",
    "\n",
    "new_corpus,desc_pred,install_pred,invoc_pred,cite_pred = classifier.inference(text)\n",
    "classifier.show_result(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "4a75a23b9764d0491f364f1e2c8d9e386a0dfe8d9a01ebe1cce74ee4fd0bbd87"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}