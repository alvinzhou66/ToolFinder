{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "from DNN import FFN\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model():\n",
    "    \n",
    "    def __init__(self,\n",
    "                 des_path,\n",
    "                 des_feat_path,\n",
    "                 install_path,\n",
    "                 install_feat_path,\n",
    "                 invoc_path,\n",
    "                 invoc_feat_path,\n",
    "                 cite_path,\n",
    "                 cite_feat_path\n",
    "                ):\n",
    "        self.desc = \"This class contains all four binary classifier\"\n",
    "        self.des_path = des_path\n",
    "        self.install_path = install_path\n",
    "        self.invoc_path = invoc_path\n",
    "        self.cite_path = cite_path\n",
    "        \n",
    "        self.des_feat_path = des_feat_path\n",
    "        self.install_feat_path = install_feat_path\n",
    "        self.invoc_feat_path = invoc_feat_path\n",
    "        self.cite_feat_path = cite_feat_path\n",
    "        \n",
    "        self.build()\n",
    "        \n",
    "    def build(self):\n",
    "        self.model_desc = torch.load(self.des_path)\n",
    "        self.model_install = torch.load(self.install_path)\n",
    "        self.model_invoc = torch.load(self.invoc_path)\n",
    "        self.model_cite = torch.load(self.cite_path)\n",
    "        \n",
    "        desc = pd.read_csv(self.des_feat_path).values\n",
    "        install = pd.read_csv(self.install_feat_path).values\n",
    "        invoc = pd.read_csv(self.invoc_feat_path).values\n",
    "        cite = pd.read_csv(self.cite_feat_path).values\n",
    "        self.desc_feat = {}\n",
    "        self.install_feat = {}\n",
    "        self.invoc_feat = {}\n",
    "        self.cite_feat = {}\n",
    "        for i in range(len(desc)):\n",
    "            self.desc_feat[desc[i][0]] = i\n",
    "        for i in range(len(install)):\n",
    "            self.install_feat[install[i][0]] = i\n",
    "        for i in range(len(invoc)):\n",
    "            self.invoc_feat[invoc[i][0]] = i\n",
    "        for i in range(len(cite)):\n",
    "            self.cite_feat[cite[i][0]] = i        \n",
    "\n",
    "        self.desc_vec = CountVectorizer(vocabulary = self.desc_feat)\n",
    "        self.install_vec = CountVectorizer(vocabulary = self.install_feat)\n",
    "        self.invoc_vec = CountVectorizer(vocabulary = self.invoc_feat)\n",
    "        self.cite_vec = CountVectorizer(vocabulary = self.cite_feat)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def inference(self,corpus):\n",
    "        new_corpus = list(map(self.lower_stopwords,corpus.split(\".\")))\n",
    "        encoded_corpus_desc = self.desc_vec.transform(new_corpus).toarray()\n",
    "        encoded_corpus_install = self.install_vec.transform(new_corpus).toarray()\n",
    "        encoded_corpus_invoc = self.invoc_vec.transform(new_corpus).toarray()\n",
    "        encoded_corpus_cite = self.cite_vec.transform(new_corpus).toarray()\n",
    "        \n",
    "        o1 = self.model_desc(torch.tensor(encoded_corpus_desc).float())\n",
    "        o2 = self.model_install(torch.tensor(encoded_corpus_install).float())\n",
    "        o3 = self.model_invoc(torch.tensor(encoded_corpus_invoc).float())\n",
    "        o4 = self.model_cite(torch.tensor(encoded_corpus_cite).float())\n",
    "        desc_pred = torch.argmax(o1,dim=1).detach().numpy()\n",
    "        install_pred = torch.argmax(o2,dim=1).detach().numpy()\n",
    "        invoc_pred = torch.argmax(o3,dim=1).detach().numpy()\n",
    "        cite_pred = torch.argmax(o4,dim=1).detach().numpy()\n",
    "        return corpus.split(\".\"),desc_pred,install_pred,invoc_pred,cite_pred\n",
    "    def lower_stopwords(self,x):\n",
    "        x = re.sub(r'[^a-zA-Z\\s]', '', x, re.I|re.A)\n",
    "        x = x.lower()\n",
    "        x = x.strip()\n",
    "        text_tokens = [word for word in word_tokenize(x) if word not in stopwords.words()]\n",
    "        return \" \".join(text_tokens)\n",
    "    def show_result(self,corpus):\n",
    "        new_corpus,desc_pred,install_pred,invoc_pred,cite_pred = self.inference(corpus)\n",
    "        for i in range(len(new_corpus)): \n",
    "            text = new_corpus[i]\n",
    "            label = []\n",
    "            if(desc_pred[i]==1):\n",
    "                label.append(\"descripetion\")\n",
    "            if(install_pred[i]==1):\n",
    "                label.append(\"installation\")\n",
    "            if(invoc_pred[i]==1):\n",
    "                label.append(\"invocation\")\n",
    "            if(cite_pred[i]==1):\n",
    "                label.append(\"citation\")\n",
    "            text += \" ->\" + str(tuple(label))\n",
    "            print(text)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas is a Python package that provides fast,flexible, and expressive data structures designed to make working with structured (tabular, multidimensional, potentially heterogeneous) and time series data both easy and intuitive ->('descripetion',)\n",
      " It aims to be the fundamental high-level building block for doing practical, real world data analysis in Python ->('descripetion',)\n",
      " Additionally, it has the broader goal of becoming the most powerful and flexible open source data analysis / manipulation tool available in any language ->('descripetion',)\n",
      " It is already well on its way toward this goal ->('descripetion', 'installation')\n",
      " ->('installation', 'invocation')\n"
     ]
    }
   ],
   "source": [
    "des_path = \"../saved_models/DNN_description.pt\"\n",
    "des_feat_path = \"../saved_models/description_feat.csv\"\n",
    "\n",
    "install_path = \"../saved_models/DNN_install.pt\"\n",
    "install_feat_path = \"../saved_models/install_feat.csv\"\n",
    "\n",
    "invoc_path = \"../saved_models/DNN_invocation.pt\"\n",
    "invoc_feat_path = \"../saved_models/invocation_feat.csv\"\n",
    "\n",
    "cite_path = \"../saved_models/DNN_citation.pt\"\n",
    "cite_feat_path = \"../saved_models/citation_feat.csv\"\n",
    "\n",
    "classifier = model(des_path,\n",
    "                 des_feat_path,\n",
    "                 install_path,\n",
    "                 install_feat_path,\n",
    "                 invoc_path,\n",
    "                 invoc_feat_path,\n",
    "                 cite_path,\n",
    "                 cite_feat_path\n",
    "            )\n",
    "corpus = \"pandas is a Python package that provides fast,\\\n",
    "flexible, and expressive data structures designed to make \\\n",
    "working with structured (tabular, multidimensional, potenti\\\n",
    "ally heterogeneous) and time series data both easy and intu\\\n",
    "itive. It aims to be the fundamental high-level building blo\\\n",
    "ck for doing practical, real world data analysis in Python. A\\\n",
    "dditionally, it has the broader goal of becoming the most power\\\n",
    "ful and flexible open source data analysis / manipulation tool a\\\n",
    "vailable in any language. It is already well on its way toward this goal.\"\n",
    "new_corpus,desc_pred,install_pred,invoc_pred,cite_pred = classifier.inference(corpus)\n",
    "classifier.show_result(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
